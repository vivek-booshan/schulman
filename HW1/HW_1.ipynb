{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c87af674",
   "metadata": {},
   "source": [
    "##  Investigating gems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe898221",
   "metadata": {},
   "source": [
    "a. We briefly discussed a data set listing diamonds and their characteristic prices and physical attributes in class.  This dataset is provided for you in a ```csv``` file.  Load the dataset ```diamonds.csv``` into your notebook as the variable ```diamonds_df```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af2f9a23",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'diamonds.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/vivek/.cache/.fr-Z2XCDe/HW1/HW_1.ipynb Cell 3\u001b[0m line \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vivek/.cache/.fr-Z2XCDe/HW1/HW_1.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vivek/.cache/.fr-Z2XCDe/HW1/HW_1.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vivek/.cache/.fr-Z2XCDe/HW1/HW_1.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m diamonds_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mdiamonds.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'diamonds.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "diamonds_df = pd.read_csv(\"diamonds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f686b59c",
   "metadata": {},
   "source": [
    "b.  Take a look at the dataframe using one of the tools we've discussed in class.  List the columns, what type of variable is in each of the columns and what datatype Python is using to store each of the columns.\n",
    "\n",
    "Are each of the datatypes consistent with the type of variable used? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52b41ec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "414dc9af",
   "metadata": {},
   "source": [
    "c.  Create a side by side boxplot of the range of prices by gem cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cdacd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56d1acc4",
   "metadata": {},
   "source": [
    "d.  What shapes are gems?  Create a scatter plot that compares the X vs Y dimensions of all of the color \"E\" gems.  What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b1b383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a46defdd",
   "metadata": {},
   "source": [
    "e. Now repeat d, but comparing x to z.  What can you say about the shapes of gems?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e170b903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a3d22e5",
   "metadata": {},
   "source": [
    "f. Here we will ask whether each of the diamonds are compact, ie the extent to which they are spherical or not.\n",
    "To do so, we will first calculate the volume that the diamond would take up if  the X-Y-Z dimensions of the diamond defined an ovoid.  In this case, the volume of the diamond would be\n",
    "\n",
    "$$ V = \\frac{4 \\pi}{3} xyz $$.\n",
    "\n",
    "Add a column ```Ovoid volume``` to the diamonds dataframe that has this hypothetical volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924f7af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfdab11c",
   "metadata": {},
   "source": [
    "g. A carat is 200 mg, so it is a measure of weight.  Given the data we have, here we will estimate the compactness of each of the diamonds by dividing the putative ovoid volume by the weight of the diamond.  Add a column to the diamonds dataframe ```Ovoid compactness``` that divides the ovoid volume by the number of carats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a3f706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73a025c2",
   "metadata": {},
   "source": [
    "h.  Now, let's use this measure to see if different cuts have different extents of compactness.  Find the average compactness for each of the cuts by grouping the diamonds by cut and taking the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689f19f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "decb787d",
   "metadata": {},
   "source": [
    "i.  Make a bar graph that compares the mean compactness of each of the cuts using the ```ggplot2``` software we discussed in class.  Use appropriate axis labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec41684a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9704a6f5",
   "metadata": {},
   "source": [
    "j.  Now let's also investigate the distribution of compactness for each cut.  Create a boxplot that compares the distribution of compactness values for each cut.  Use appropriate axis labels for your graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5303f79b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef5b3272",
   "metadata": {},
   "source": [
    "## Electrophysiology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb6e78b",
   "metadata": {},
   "source": [
    "a.  The file ```conductance_data_for_seeds_v2.xlsx``` lists a set of measured values of conductance of single macromolecular structures.  There are three sheets in the dataframe. Load each of the sheets of the Excel file into Python in three dataframes, one for each sheet, so that the headers in the spreadsheet become the column names in your dataframe.  Your three dataframes should be stored in an array ```conductance_df_array``` in indices 0-2 in the order the sheets are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a583b619",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2667b81a",
   "metadata": {},
   "source": [
    "b.  You can see that each of the sheets has a title -- the type of structure being characterized.  Combine this data into a single dataframe ```conductances``` in which the type of structure being characterized is listed in a column as a categorical variable.  Do this by reading the names of the sheets from the Excel file using Python, not manually (later you may need to do this for many more sheets, so this is a good skill to learn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5e3f79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7309a7e4",
   "metadata": {},
   "source": [
    "c.  You can notice that the data is not stored so that there is one observation per row.  Write code to transform ```conductances``` into a tidy dataset in which each observation is in its own row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e2b694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1142710",
   "metadata": {},
   "source": [
    "d.  Create a histogram of all of the conductances as a single plot.  Label your axes with appropriate names and units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124ca060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4adea0c5",
   "metadata": {},
   "source": [
    "e.  Now create a faceted histogram in which the each of the three types of structures are plotted in their own histogram side by side.   Label your axes with appropriate names and units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a757d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df012828",
   "metadata": {},
   "source": [
    "f.  What can you conclude about the conductances of the different structures from the histograms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994a1433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f51f4e13",
   "metadata": {},
   "source": [
    "## Filtering and joining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530fa972",
   "metadata": {},
   "source": [
    "a.  In this problem we are going to consider data from a survey of countries by their happiness in 2017, in the file ```happiness_2017.csv``` and data about countries of the world ```world_countries.csv```.  Load each of these into two dataframes, ```happiness``` and ```country_data```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49625280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20840600",
   "metadata": {},
   "source": [
    "Inspect each of the dataframes.  You can see that the country data dataframe has extensive demographic data to support the happiness dataset.  We are going to make some comparisons by joining these datasets and plot the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0ee302",
   "metadata": {},
   "source": [
    "b.  Use merging operations to add information about literacy to the happiness dataframe.  Create a scatter plot that relates literacy to happiness.  Use appropriate axis labels, and color code the datapoints by region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367bd626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5856f007",
   "metadata": {},
   "source": [
    "c.  Now let's do a similar analysis, in which we relate the fraction of people who have phones in a country to the amount of corruption in a country.  Group the results by region and create a scatter plot of the results (there will be many fewer regions than countries).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d7c7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bc3ae4e",
   "metadata": {},
   "source": [
    "f.  Now let's take a look at the countries that are very generous. Create a dataframe that contains the ten countries with highest generosity scores ```most_generous``` and another with those 10 rated as least generous ```least_generous```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243c89c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d87e4c4",
   "metadata": {},
   "source": [
    "g.  Add a column listing the amount of arable land to each of the columns of the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb0a352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "709df79a",
   "metadata": {},
   "source": [
    "h.  Now compute the mean amount of arable land for each of these sets of countries.  Store these in ```mg_arable_mean``` and ```lg_arable_mean```.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d9df37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e069f4f6",
   "metadata": {},
   "source": [
    "i.  To understand whether these differences are meaningful, let's take a look at the distribution of arable land.  Generate the summary statistics for arable land:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b5afd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13452f69",
   "metadata": {},
   "source": [
    "j.  Now create a scatter plot that helps you visualize the relationship between the amount of arable land of all the countries in the world.  Add a regression line relating these two values, and calculate the correlation coefficient of these two terms.  \n",
    "Based the plot and this information, how would you characterize the relationship between arable land and generosity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea54516c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "feb2c81b",
   "metadata": {},
   "source": [
    "## Cleaning genomics data (540.605 only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2527c2",
   "metadata": {},
   "source": [
    "The data in the spreadsheet ```data-for-analysis-miRNA-cancer``` is a set of next-generation sequencing reads for a range of tissue samples.  The sample names are given by codes on the second row of the dataframe.  The possible miRNA sequences that are read are the rows and three attributes for each tissue sample are given, the total number of reads, the read frequency and whether the reads were crossmapped. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b816ad",
   "metadata": {},
   "source": [
    "The data for this problem was kindly provided by the authors of this article:\n",
    "Zhang, C. et al. Nat. Nanotechnol. https://doi.org/10.1038/s41565020-0699-0 (2020)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0633c9",
   "metadata": {},
   "source": [
    "a.  This data is not in tidy format.  Clean up the data so that each observation, *i.e.* each tissue sample is a row and the frequency and number of reads of each type of miRNA are the columns (we will not consider the cross-mapped attribute for this exercise.)  Store the result in ```miRNA_tidy```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5f3068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23698687",
   "metadata": {},
   "source": [
    "b.  Here the tissue samples are labeled with a standard TGCA barcode.  A description of how TGCA barcodes work is found here:\n",
    "https://docs.gdc.cancer.gov/Encyclopedia/pages/TCGA_Barcode/\n",
    "\n",
    "The specimen ID also contains the diagnosis. Read over this description to understand how this information is encoded.\n",
    "\n",
    "Write a python function ```patient_diagnosis``` that takes the specimen ID and returns 'normal' if the specimen type is normal and 'tumor' if the specimen type is of a tumor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ccb46b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bba6681",
   "metadata": {},
   "source": [
    "c.  Use this function to add a column to create a separate dataframe ```barcode_values``` with two columns: ````TGCA_barcode``` and ```diagnosis``.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b796ae0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2de6c5e",
   "metadata": {},
   "source": [
    "d.  Now let's try to take a look at this data to attempt to identify miRNAs that might on their own be indicative of a patient having a tumor.  Add the ```diagnosis``` column to the ```miRNA_tidy``` dataframe by merging that dataframe with the dataframe you made in c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8033d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f377a119",
   "metadata": {},
   "source": [
    "e.  Now group your data by diagnosis and create a summary of the mean reads per million of each of the types of miRNA.  Call this ```mean_freq_by_diagnosis```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20758ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6cc7d13",
   "metadata": {},
   "source": [
    "f.  Now let's filter this dataframe to find miRNA values that might differ.  Create a table of all miRNA values for which the mean reads per million is at least 25% higher on average for tumor samples vs normal samples. Store that in the variable ```tumor_25_higher```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a1441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47cd07db",
   "metadata": {},
   "source": [
    "g.  Repeat (f) but for reads per million that are at least 25% *lower* on average. Store that in the variable ```tumor_25_lower```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd876dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6b86dbf",
   "metadata": {},
   "source": [
    "h.  Now let's try one more thing -- it will be hard to count on reads per million below about 50.  Combine your results from (f) and (g) but restrict your list to only those miRNA whose mean reads per million is at least 50.  Store that in the variable ```tumor_different_and_frequent``` "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
